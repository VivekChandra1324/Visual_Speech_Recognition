{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n"
      ],
      "metadata": {
        "id": "TgOxM2RLIsAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, MaxPooling3D, Dropout, Dense, TimeDistributed, Flatten, GRU, Bidirectional, ZeroPadding3D\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layers\n",
        "model.add(Conv3D(32, (3, 3, 3), strides=(1, 1, 1), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(75, 64, 64, 1), name='conv1'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(64, (3, 3, 3), strides=(1, 1, 1), activation='relu', kernel_initializer='he_normal', padding='same', name='conv2'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(96, (3, 3, 3), strides=(1, 1, 1), activation='relu', kernel_initializer='he_normal', padding='same', name='conv3'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# Recurrent Layers\n",
        "model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(char_to_num.vocabulary_size() + 1, kernel_initializer='he_normal', activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX3PoHAHNeGU",
        "outputId": "9ecaaf06-fa72-4694-bc4d-86d6a5ed0c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1 (Conv3D)              (None, 75, 64, 64, 32)    896       \n",
            "                                                                 \n",
            " max1 (MaxPooling3D)         (None, 75, 32, 32, 32)    0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 32, 32, 32)    0         \n",
            "                                                                 \n",
            " conv2 (Conv3D)              (None, 75, 32, 32, 64)    55360     \n",
            "                                                                 \n",
            " max2 (MaxPooling3D)         (None, 75, 16, 16, 64)    0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 16, 16, 64)    0         \n",
            "                                                                 \n",
            " conv3 (Conv3D)              (None, 75, 16, 16, 96)    165984    \n",
            "                                                                 \n",
            " max3 (MaxPooling3D)         (None, 75, 8, 8, 96)      0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 75, 8, 8, 96)      0         \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 75, 6144)          0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 75, 512)           9833472   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 75, 512)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 75, 512)           1182720   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 75, 512)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 75, 41)            21033     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11259465 (42.95 MB)\n",
            "Trainable params: 11259465 (42.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint_callback, schedule_callback]\n",
        ")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VQl5U3MS2uM",
        "outputId": "33e4da1e-3a4b-46e3-c5b4-ecd57de7cfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "800/800 [==============================] - 59s 57ms/step - loss: 71.4971 - val_loss: 94.2230 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 64.0175 - val_loss: 89.8872 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 61.2926 - val_loss: 94.4096 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 58.3685 - val_loss: 77.2424 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 55.6191 - val_loss: 74.4212 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 52.2267 - val_loss: 65.7331 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 49.2044 - val_loss: 63.2733 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 47.0273 - val_loss: 60.7501 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 45.3770 - val_loss: 68.4591 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 43.6799 - val_loss: 65.0677 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 42.6970 - val_loss: 69.0602 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 41.5067 - val_loss: 58.1360 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 41.8587 - val_loss: 46.9419 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 41.0192 - val_loss: 44.5375 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 40.0812 - val_loss: 40.4207 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 39.3570 - val_loss: 38.2715 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 39.3530 - val_loss: 38.4979 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 39.4262 - val_loss: 39.5049 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 39.7304 - val_loss: 35.5760 - lr: 1.0000e-04\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 38.5615 - val_loss: 35.6016 - lr: 1.0000e-04\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 37.2412 - val_loss: 35.7232 - lr: 1.0000e-04\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 35.7245 - val_loss: 39.7164 - lr: 1.0000e-04\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 35.2435 - val_loss: 34.5793 - lr: 1.0000e-04\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 38.0667 - val_loss: 37.3420 - lr: 1.0000e-04\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 46s 57ms/step - loss: 39.0325 - val_loss: 37.1195 - lr: 1.0000e-04\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 39.0785 - val_loss: 50.4436 - lr: 1.0000e-04\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 40.2998 - val_loss: 36.6963 - lr: 1.0000e-04\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 37.7979 - val_loss: 36.6878 - lr: 1.0000e-04\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 36.6496 - val_loss: 36.0778 - lr: 1.0000e-04\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 35.9459 - val_loss: 34.9322 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('lip_reading_model_30.h5', custom_objects={'CTCLoss': CTCLoss})\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=40,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint_callback, schedule_callback]\n",
        ")\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii67I8B8AB0g",
        "outputId": "c617fa0c-0453-40f7-b63f-73c65ba1d687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "800/800 [==============================] - 50s 54ms/step - loss: 35.8827 - val_loss: 41.3265 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 34.6997 - val_loss: 39.2969 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 33.7552 - val_loss: 38.6371 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 35.1246 - val_loss: 38.8462 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 33.0548 - val_loss: 37.2897 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 39.6449 - val_loss: 40.2726 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 37.9801 - val_loss: 35.3702 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 34.8665 - val_loss: 36.9579 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 33.1588 - val_loss: 33.4719 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 32.1538 - val_loss: 32.9065 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 32.0019 - val_loss: 33.7190 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 30.7570 - val_loss: 31.7542 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 29.9233 - val_loss: 32.3630 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 29.2072 - val_loss: 32.6633 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 27.7024 - val_loss: 31.8063 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 27.7107 - val_loss: 33.4475 - lr: 1.0000e-04\n",
            "Epoch 17/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 26.2403 - val_loss: 29.7887 - lr: 1.0000e-04\n",
            "Epoch 18/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 27.0521 - val_loss: 32.5474 - lr: 1.0000e-04\n",
            "Epoch 19/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 25.0861 - val_loss: 29.5471 - lr: 1.0000e-04\n",
            "Epoch 20/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 28.4077 - val_loss: 31.9015 - lr: 1.0000e-04\n",
            "Epoch 21/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 25.7545 - val_loss: 64.3026 - lr: 1.0000e-04\n",
            "Epoch 22/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 26.2097 - val_loss: 34.6137 - lr: 1.0000e-04\n",
            "Epoch 23/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 25.3808 - val_loss: 29.1279 - lr: 1.0000e-04\n",
            "Epoch 24/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 25.5365 - val_loss: 33.4243 - lr: 1.0000e-04\n",
            "Epoch 25/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 24.7012 - val_loss: 25.9434 - lr: 1.0000e-04\n",
            "Epoch 26/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 32.5043 - val_loss: 33.3976 - lr: 1.0000e-04\n",
            "Epoch 27/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 27.9867 - val_loss: 27.1991 - lr: 1.0000e-04\n",
            "Epoch 28/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 23.2956 - val_loss: 23.4160 - lr: 1.0000e-04\n",
            "Epoch 29/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 23.4763 - val_loss: 28.7136 - lr: 1.0000e-04\n",
            "Epoch 30/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 23.1128 - val_loss: 26.4366 - lr: 1.0000e-04\n",
            "Epoch 31/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 21.6173 - val_loss: 26.7632 - lr: 9.0484e-05\n",
            "Epoch 32/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 20.8913 - val_loss: 32.0624 - lr: 8.1873e-05\n",
            "Epoch 33/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 25.1756 - val_loss: 33.0472 - lr: 7.4082e-05\n",
            "Epoch 34/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 21.7143 - val_loss: 40.6349 - lr: 6.7032e-05\n",
            "Epoch 35/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 20.3219 - val_loss: 30.6544 - lr: 6.0653e-05\n",
            "Epoch 36/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 19.7796 - val_loss: 30.1533 - lr: 5.4881e-05\n",
            "Epoch 37/40\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 20.5945 - val_loss: 35.8781 - lr: 4.9659e-05\n",
            "Epoch 38/40\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 18.9422 - val_loss: 37.3325 - lr: 4.4933e-05\n",
            "Epoch 39/40\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 18.5530 - val_loss: 33.3351 - lr: 4.0657e-05\n",
            "Epoch 40/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 19.1159 - val_loss: 33.2967 - lr: 3.6788e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('lip_reading_model_70.h5', custom_objects={'CTCLoss': CTCLoss})\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint_callback, schedule_callback]\n",
        ")\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7K9WYArKljm",
        "outputId": "95b64248-d814-4225-8811-6d08040826ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "800/800 [==============================] - 50s 54ms/step - loss: 17.6951 - val_loss: 31.1245 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 17.2806 - val_loss: 34.4926 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 17.1052 - val_loss: 38.7013 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 23.1054 - val_loss: 29.0075 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 17.4616 - val_loss: 36.4817 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "800/800 [==============================] - 43s 53ms/step - loss: 16.3180 - val_loss: 39.8795 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 24.2395 - val_loss: 26.4560 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 17.1416 - val_loss: 27.6093 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 15.4327 - val_loss: 26.3384 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 14.7036 - val_loss: 33.6961 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 14.7595 - val_loss: 38.9364 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 13.9637 - val_loss: 37.2929 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 13.4885 - val_loss: 33.4072 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 12.8230 - val_loss: 37.2203 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 15.0486 - val_loss: 36.3989 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "800/800 [==============================] - 44s 55ms/step - loss: 13.9212 - val_loss: 33.4734 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 12.3822 - val_loss: 34.8367 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 15.3923 - val_loss: 32.9720 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 13.4062 - val_loss: 35.7910 - lr: 1.0000e-04\n",
            "Epoch 20/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 12.3026 - val_loss: 33.6040 - lr: 1.0000e-04\n",
            "Epoch 21/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 11.0979 - val_loss: 35.3500 - lr: 1.0000e-04\n",
            "Epoch 22/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 11.4692 - val_loss: 34.5194 - lr: 1.0000e-04\n",
            "Epoch 23/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 11.9951 - val_loss: 34.9087 - lr: 1.0000e-04\n",
            "Epoch 24/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 10.8766 - val_loss: 36.0908 - lr: 1.0000e-04\n",
            "Epoch 25/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 10.7524 - val_loss: 30.6270 - lr: 1.0000e-04\n",
            "Epoch 26/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 10.5692 - val_loss: 32.4513 - lr: 1.0000e-04\n",
            "Epoch 27/30\n",
            "800/800 [==============================] - 43s 53ms/step - loss: 10.3162 - val_loss: 36.2482 - lr: 1.0000e-04\n",
            "Epoch 28/30\n",
            "800/800 [==============================] - 42s 53ms/step - loss: 9.6936 - val_loss: 37.4516 - lr: 1.0000e-04\n",
            "Epoch 29/30\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 9.8982 - val_loss: 34.7018 - lr: 1.0000e-04\n",
            "Epoch 30/30\n",
            "800/800 [==============================] - 41s 52ms/step - loss: 10.6603 - val_loss: 36.7657 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('lip_reading_model_100.h5', custom_objects={'CTCLoss': CTCLoss})\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
        "schedule_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=40,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint_callback, schedule_callback]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phOB0WjySgAh",
        "outputId": "9d0ff1c6-b05d-4aa9-9cff-35c73f26add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "800/800 [==============================] - 56s 54ms/step - loss: 9.7833 - val_loss: 39.7818 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 9.7106 - val_loss: 32.4991 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.3723 - val_loss: 33.4720 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.5207 - val_loss: 33.2427 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 8.1888 - val_loss: 35.8745 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 12.0621 - val_loss: 32.1284 - lr: 1.0000e-04\n",
            "Epoch 7/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.5041 - val_loss: 32.3934 - lr: 1.0000e-04\n",
            "Epoch 8/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 10.9178 - val_loss: 33.9085 - lr: 1.0000e-04\n",
            "Epoch 9/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 8.8506 - val_loss: 37.0887 - lr: 1.0000e-04\n",
            "Epoch 10/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 8.0829 - val_loss: 37.4765 - lr: 1.0000e-04\n",
            "Epoch 11/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 7.4200 - val_loss: 38.9980 - lr: 1.0000e-04\n",
            "Epoch 12/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 7.0408 - val_loss: 43.8430 - lr: 1.0000e-04\n",
            "Epoch 13/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 6.8541 - val_loss: 37.7434 - lr: 1.0000e-04\n",
            "Epoch 14/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 10.7293 - val_loss: 41.5195 - lr: 1.0000e-04\n",
            "Epoch 15/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 8.5001 - val_loss: 34.6809 - lr: 1.0000e-04\n",
            "Epoch 16/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 7.6503 - val_loss: 37.1775 - lr: 1.0000e-04\n",
            "Epoch 17/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 7.3734 - val_loss: 36.0772 - lr: 1.0000e-04\n",
            "Epoch 18/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.1894 - val_loss: 37.0585 - lr: 1.0000e-04\n",
            "Epoch 19/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 7.5257 - val_loss: 40.3278 - lr: 1.0000e-04\n",
            "Epoch 20/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 7.6122 - val_loss: 35.2128 - lr: 1.0000e-04\n",
            "Epoch 21/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 6.7351 - val_loss: 40.7124 - lr: 1.0000e-04\n",
            "Epoch 22/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 6.7757 - val_loss: 35.5701 - lr: 1.0000e-04\n",
            "Epoch 23/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 6.4108 - val_loss: 34.6538 - lr: 1.0000e-04\n",
            "Epoch 24/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 6.1580 - val_loss: 41.6687 - lr: 1.0000e-04\n",
            "Epoch 25/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 6.0007 - val_loss: 40.7600 - lr: 1.0000e-04\n",
            "Epoch 26/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 5.7005 - val_loss: 39.5755 - lr: 1.0000e-04\n",
            "Epoch 27/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 5.8297 - val_loss: 40.5356 - lr: 1.0000e-04\n",
            "Epoch 28/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 8.3621 - val_loss: 41.8665 - lr: 1.0000e-04\n",
            "Epoch 29/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 12.8493 - val_loss: 35.0571 - lr: 1.0000e-04\n",
            "Epoch 30/40\n",
            "800/800 [==============================] - 40s 51ms/step - loss: 9.9523 - val_loss: 31.8833 - lr: 1.0000e-04\n",
            "Epoch 31/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 12.8457 - val_loss: 30.9324 - lr: 9.0484e-05\n",
            "Epoch 32/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.8927 - val_loss: 29.5935 - lr: 8.1873e-05\n",
            "Epoch 33/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 8.1328 - val_loss: 33.9929 - lr: 7.4082e-05\n",
            "Epoch 34/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 10.8668 - val_loss: 38.2470 - lr: 6.7032e-05\n",
            "Epoch 35/40\n",
            "800/800 [==============================] - 40s 50ms/step - loss: 9.1768 - val_loss: 32.5706 - lr: 6.0653e-05\n",
            "Epoch 36/40\n",
            "800/800 [==============================] - 42s 52ms/step - loss: 8.4261 - val_loss: 32.4730 - lr: 5.4881e-05\n",
            "Epoch 37/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 7.5702 - val_loss: 36.4340 - lr: 4.9659e-05\n",
            "Epoch 38/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 6.5791 - val_loss: 37.4019 - lr: 4.4933e-05\n",
            "Epoch 39/40\n",
            "800/800 [==============================] - 43s 53ms/step - loss: 6.4921 - val_loss: 38.7386 - lr: 4.0657e-05\n",
            "Epoch 40/40\n",
            "800/800 [==============================] - 41s 51ms/step - loss: 6.4180 - val_loss: 38.0945 - lr: 3.6788e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_display(dataset, num_samples=5):\n",
        "    for i, batch in enumerate(dataset.take(num_samples)):\n",
        "        videos, labels = batch\n",
        "        pred_probs = model.predict(videos)\n",
        "        pred_labels = tf.argmax(pred_probs, axis=-1)\n",
        "        pred_texts = num_to_char(pred_labels)\n",
        "        true_texts = num_to_char(labels)\n",
        "\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        # Decode bytes to string if necessary\n",
        "        true_text_str = ''.join([t.decode() if isinstance(t, bytes) else t for t in true_texts.numpy()[0]]).strip()\n",
        "        pred_text_str = ''.join([p.decode() if isinstance(p, bytes) else p for p in pred_texts.numpy()[0]]).strip()\n",
        "        print(f\"  True Text: {true_text_str}\")\n",
        "        print(f\"  Predicted Text: {pred_text_str}\")\n",
        "\n",
        "predict_and_display(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzmfBkwaTByr",
        "outputId": "9b1ba4bd-66c5-4cae-dd84-3097e72c1862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Sample 1:\n",
            "  True Text: set blue with o one soon\n",
            "  Predicted Text: set  bluue   in  y  oone  sooonn\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Sample 2:\n",
            "  True Text: set blue with o two please\n",
            "  Predicted Text: set bbluue  with t  touo  pleaasee\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Sample 3:\n",
            "  True Text: set blue with o three again\n",
            "  Predicted Text: sett bbluee  wit  r  teve  agaain\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Sample 4:\n",
            "  True Text: set blue with o zero now\n",
            "  Predicted Text: set  bluue   in  z  twwo  nooww\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Sample 5:\n",
            "  True Text: set blue with u four now\n",
            "  Predicted Text: set bbluue   in  r  four  nowww\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}